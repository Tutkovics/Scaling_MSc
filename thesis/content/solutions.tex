%----------------------------------------------------------------------------
\chapter{Megoldási lehetőségek}
\label{sec:solutions}
%----------------------------------------------------------------------------

Ebben a fejezetben szeretném bemutatni, hogy a korábban \aref{sec:results} fejezetben látott mérések alapján milyen megoldási lehetőségek jöhetnek számításba.
Természetesen minden bemutatott megoldásnak megvan a saját erőssége és gyengesége, amiket a következő alfejezetekben részletesen is ismertetek.

%----------------------------------------------------------------------------
\section{Feltárt probléma rövid összefoglalása}
%----------------------------------------------------------------------------

A megoldási lehetőségek bemutatása előtt szeretném röviden bemutatni a problémát és a felvetést, amire keressük a megoldást.
A mérési eredmények alapján arra jutottam, hogy a mikroszolgáltatások közötti szabályozatlan kommunikáció miatt egy túlterhelt rendszer nem képes optimális működést biztosítani.
Létezik egy átbukási pont, amikor a beérkező kéréseket az alkalmazás már nem képes időben kiszolgálni, mert az egyik komponense túlterhelt állapotba kerül.
Ilyenkor a beérkező kérések továbbra is fogadásra kerülnek és elkezdődik a rendszerben lévő pufferek megtöltése.
Ez egy öngerjesztő folyamatot indít meg, ahol a hosszabb sorbaállás, a folyamatos túlterheltség miatt aránylag egyre kisebb lesz a sikeres kiszolgálások száma.
A hatékonytalan működést tovább rontja, hogy az előre beállított idő túllépése után bontjuk a kapcsolatot, azonban ezt az alkalmazás nem tudja lekezelni.
Nem létezik implementált megoldás arra az esetre, hogy az ilyen kérések által keltett az egyéb alkalmazás egységek terhelését megszüntesse.
Értelemszerűen ebben az esetben felesleges még a backend oldalán elvégezni az erőforrás intenzív feladatot, amikor az azt kiváltó eredeti kérés már eldobásra került.

A tapasztalt működés több irányból is megközelíthető.
Egyik ilyen irány, hogy az egyes komponensek darabszámát automatikus skálázó segítségével határozzuk meg.
Ezzel lehetőséget kapunk, hogy előre meghatározott cél processzorhasználati értékhez rendeljük a skálázási döntéseket. 
A megoldás észleli az esetlegesen terhelt komponenseket és megpróbálja azokat horizontálisan skálázni.
Amennyiben limitált erőforrással rendelkezünk a klaszteren belül, akkor elmondható, hogy léteznek olyan skálázási helyzetek, melyeket a Kubernetes jelenlegi skálázója nem tud ideálisan kezelni.
Ez a működés onnan fakad, hogy a futó alkalmazásról nem rendelkezik globális ismerettel, csak az egyes független szolgáltatásokat kezeli a többitől függetlenül.
Nem tudja megítélni, hogy a rendszer kiszolgálási paraméterek növeléséhez hova 

Másik megközelítés, hogy a rendszerbe beérkező kéréseket szabályozzuk vagy pedig észleljük a túlterhelt állapotban lévő komponenseket és valamilyen logikával próbáljuk csökkenteni azok terheltségi szintét.

%----------------------------------------------------------------------------
\section{Lehetséges eszközök}
%----------------------------------------------------------------------------

További feladatom volt, hogy keressek olyan kiegészítést vagy javaslatot, ami feltárt hiányosságokat javítani tudná.
A szimulációk futtatása alatt és források keresése közben számos megoldási lehetőség felmerült.
A bemutatott eszközök elemzése során látni fogjuk, hogy kicsit más megközelítésből és a probléma más aspektusát célozva próbálja a feltárt hatásokat csökkenteni.

Az egyes eszközök értékelésénél az is fontos szempont volt, hogy a lehető legkevesebb módosítást kelljen végrehajtani az alkalmazás oldalán.
Ez fontos, mert a megvalósítani kívánt feladat nem tartozik szorosan az alkalmazáshoz és ideális esetben teljesen transzparens módon működne.
Természetesen több dolgot is mérlegelni kell az adott helyzetben ideálisnak ítélt megoldás kiválasztása közben.

Fontos azt is megfontolni, hogy egy az infrastrukturális részekre hatást gyakorló eszköz milyen információk alapján engedjük, hogy dolgozzon.
Természetesen minél több információval rendelkezünk az adott alkalmazást illetően, annál közelebbi megoldásokat tudunk nyújtani az optimálishoz.
Például, ha egy okos skálázónak rálátást adunk az alkalmazás hálózatára, az egyes egységek által használt erőforrásokra, a köztük lévő kapcsolatra és esetleg saját metrikákat is kivezetünk, akkor a skálázási döntés meghozatalában ezeket mind számításba tudjuk venni.
Másik oldalról viszont aggályos lehet, ha ilyen szintű monitorozást és belelátást biztosítunk, mert ezáltal következtetéseket tudunk levonni a futtatott alkalmazásról.
Ez pedig bizonyos esetekben az ügyfél érdekeit sértheti.


\subsection{Beépített állapotjelzők}
%----------------------------------------------------------------------------
A Kubernetes kapszulák létrehozása közben, beépített módon lehetőségünk van a kapszula állapotáról jelzési pontokat meghatározni.
Ezzel a megoldással sokrétűen használható funkciókat kapunk, amivel közvetetten több dolog befolyásolására nyílik lehetőségünk.
Három jelzési módszerünk van, amit három különböző esetre találtak ki.
Az alapvető felvetés onnan fakad, hogy különböző, gyakran előforduló helyzetekre adnak megoldási lehetőségeket különálló működésük által.
Az egyes állapotjelzők ideális használati módját az alábbi szituációkkal szeretném szemléltetni.

\begin{enumerate}
    \item \textbf{Életteli próba (liveness probe)} - Előfordulhat, hogy az alkalmazásunk valamilyen bemenetek következtében holtponti állapotba kerül, amit nehéz lenne kívülről észrevenni, viszont külső behatás nélkül nem tudna továbblépni belőle. 
    Illetve egyéb okok miatt is kerülhet olyan állapotba, amikor a vizsgált alkalmazás nem képes ellátni a működését, mindezt különösebb hiba és kilépés nélkül.
    Szerencsére az ilyen esetek nem számítanak különösnek és hamar fel is lehet oldani az egység újraindításával, amit az életteli próbával tudunk kezelni.
    Ez egy teljesen ideális implementáció esetén nem fog gondot okozni, hiszen a kapszulák nem tartalmaznak, tárolnak fontos adatokat és állapotokat.
    Egy újraindítás idő- és költséghatékonyabb megoldás, mintha az egész rendszer funkcionális működését veszélyeztetnénk.

    \item \textbf{Indítási próba (startup probe)} - Eshetőség, hogy az alkalmazás elindítása után még el kell végezni pár inicializációt, mielőtt a külső kérések kiszolgálását elkezdhetné.
    Ebben az esetben is tudatni kell az infrastruktúra részére, hogy a jelenlegi állapotában még nem áll készen a működésre.
    Nagy hibázási lehetőséget rejtene magába, ha erre a korábban látott  életteli próbát használjuk, mert nehéz kiszámítani mennyi időt fog igénybe venni a komponens elindulása.
    Külön emiatt létezik az indítási próba, ami csak akkor fogja az adott kapszula állapotát készenléti státuszba sorolni, ha sikeresen lefutott a próba.

    \item \textbf{Készenléti próba (readiness probe)} - Tegyük fel, hogy van egy szolgáltatásunk, ahol nagy fájlok feltöltésére van lehetőségünk.
    Ez egy időigényesebb feladat lesz, miközben az alkalmazásunkat nem szeretnénk további kérésekkel terhelni.
    Ebben az esetben meg kell várni a korábban érkező kérés kiszolgálását és csak utána van lehetőségünk fogadni a többit.
    Ilyen helyzetben tudjuk használni a készenléti próba jelzést. 
    Amennyiben a próba sikertelen vol, tehát jelenleg nem engedhetünk új kiszolgálást, akkor a kapszula IP címe ki fog kerülni erre az időszakra a hozzá tartozó \textit{Service} alól, így forgalom se fog eljutni hozzá. 
    
\end{enumerate}

A fentebb bemutatott eszközök megkönnyítik a robusztus rendszerek építését.
Segítségükkel az előforduló hibák gyors javítására tudunk fókuszálni, és nem cél azok mindenáron történő megakadályozása.
A szemléletmód kihasználja, hogy az új konténerek elindítása általában pár másodperc alatt megtörténik.
Továbbá ezen folyamat által egy öngyógyító tulajdonságot is kap a rendszer, amivel a megbízhatósága is javulni fog. 

Ennek ellenére körültekintően kell ezeket az eszközöket is használni, hiszen rossz konfiguráció esetén mi magunk tehetjük működésképtelenné a rendszert.
Például, hibás beállítás esetén az életteli próba hajlamos állandóan újraindítani az alkalmazást. Vagy a készenléti próba miatt egyes komponens egységek nem fognak annyi kérést kapni, amit azok valóban képesek lennének kiszolgálni.

\paragraph{Módszer tesztelése}
A következő feladat az volt, hogy a bemutatott állapotjelzők használatával ismét el kellett végezni a korábbi mérést és megnézni az elért hatását.
Számomra a készenléti probléma volt a legérdekesebb, hiszen ez a megoldás ad lehetőséget arra, hogy addig ne érkezzen kiszolgálandó kérés az adott alkalmazás egységhez, amíg egy bizonyos állapot teljesül.

A mérés elvégzéséhez fel kellett készíteni a korábban megírt operátort, hogy a \textit{Deployment} létrehozása közben egy készenléti próba definíciót is építsen bele. 
Valamint minden egyes alkalmazásegységnek rendelkeznie kell egy olyan végponttal, ami nem jelent számottevő többlet terhelést, és az ide érkező kérések kiszolgálása alapján tudja megmondani a rendszer jelenlegi terheltségét. 
Amennyiben a próba sikertelen, tehát a rendszer túlterhelt állapotban van, akkor nem szabad számára több kérést továbbítani, amíg nem csökken a kiszolgálásra váró kérések sora.

% MultiFE & SingleBE with Readiness probe -------------------------------------------------------
\begin{figure}[!ht]
\centering
\includegraphics[width=150mm, keepaspectratio]{figures/multiFE-singleBE-readinessprobe-sum-regenerate.png}
\caption{Korábbi szimuláció megismétlése készenléti próbával}
\label{fig:readiness-probe-measurement}
\end{figure}

A módszer hatékonyságának vizsgálata érdekében arra gondoltam, hogy egy korábban már bemutatott mérést fogok megismételni, csak kibővítve az állapotjelzővel.
Ehhez \aref{subsec:3FE_1BE_stack} alfejezetben bemutatott mérést választottam.
A szimuláció elvégzését követően kapott eredmények sajnos nem váltották be a hozzájuk fűzött reményeket, és nem javultak számottevő mértékben a kiszolgálási paraméterek.
Összességben hasonló tendenciát lehetett megfigyelni, mint a korábbi, próba nélküli mérés esetén. 
A mérés elején folyamatosan emelkedett a kiszolgált kérések száma, azonban az eredeti méréssel azonos időben és helyen megindult a meredek visszaesés is.
Ez amiatt lehetett, mert a beérkező kérések kiszolgálása továbbra sem tudott megtörténni az öt másodperces időkorláton belül, ahogy az \aref{fig:readiness-probe-measurement} ábra tetején is látszik.
Az eredeti méréssel azonos tendenciát figyelhetünk meg és azonos helyen van az átbukási pont, amikor a rendszer terhelését növelve drasztikusan visszaesik a sikeres kiszolgálások száma.
Ebben az esetben is azt látjuk, hogy a backend CPU felhasználása hamar egy plafonba ütközik, amin túl kitörni már nem tud.
Illetve ezzel párhuzamosan a költséghatékony frontend továbbra is fogadja a beérkező kéréseket, ami miatt további erőforrásokat fog elhasználni.
A korábbi méréseknél a backend részére 2000 mCPU és a frontend kapszuláknak pedig 1000 mCPU limitáció volt beállítva.
Ezen limitek a mostani méréseknél sem változtak, azonban az ábráról tisztán leolvasható, hogy a felhasznált erőforrás mennyisége a korábbitól jelentősen elmaradt.
Azt láthatjuk, hogy a beállított próba hatására a backend és a frontend által elhasznált erőforrások mennyisége lecsökkent.
Az lehet erre a magyarázat, hogy a backend, amikor érzékelte, hogy kezd túlterhelődni, akkor egy kisebb időszakra szüneteltette a kérések fogadását, ami miatt arányaiban csökkent a mérések során elhasznált processzor mennyisége.

Sajnos azonban a beállított próbával sem sikerült elérni, hogy a kiszolgálási mutatók megfelelő mértékben javuljanak, hiszen a megismételt mérésben is egy megadott pont után visszaesett a sikeres kiszolgálások száma. Jelen állásban minden alkalmazás egység saját magának a terheltségét tudja monitorozni, ami miatt hiába van a sor végén lévő backend komponens leterhelve, ezt a frontend még nem érzékeli és továbbra is fogadni fogja a felé irányított kéréseket.
Esetleg érdemes lehet további finomításokat bevezetni és egy saját szkripttel ellenőrizni a láncolat végén elhelyezkedő backend állapotát a frontend oldaláról is.
Ezzel megoldhatóvá válna, hogy a lassú komponenshez igazodva tudjuk a kéréseket fogadni már a kiszolgálási lánc elején.

Természetesen a vázolt megoldás is tartalmaz néhány kifogásolható aspektust. 
Az ilyen módon összeállított rendszer egy másik komponens állapotát monitorozza és ez alapján tudja a saját készenléti állapotjelzőjét állítani. 
Statikusan kell ezen próbákat beállítani és a terhelés változásával változhat a szűk keresztmetszet is.
Például egy valódi forgalmat elemezve rendszeresen megjelenik, hogy periodikusan lesznek terhelve a komponensek.
Nap elején elképzelhető, hogy a bejelentkeztető komponens lesz túlterhelt és szűk keresztmetszet, míg nap közben pedig az adatok validációjáért felelős szolgáltatás.
Ezen változásokat pedig nehéz lehet lekezelni, egy egyszerűbb szkripttel.


\subsection{Konténer specifikus metrikák alapján}
\label{subsec:container_metric_scaling}
%----------------------------------------------------------------------------
Következőnek ismertetett megoldási javaslat szintén a beépített Kubernetes erőforrásokat és azok funkcióit kívánja felhasználni.
Ezen megoldásoknak előnye, hogy a klaszter oldaláról nem igényelnek nagy mértékű többlet fejlesztést és támogatást, hiszen ezek a funkciók valószínűleg rendelkezésre állnak már a rendszerben vagy pedig könnyen telepíthetőek.
A mérleg másik oldalán ezen megoldások az alkalmazás oldalán igényelnek fejlesztéseket vagy pedig a helyes konfiguráció okozhat kihívást.

Még korábban, \aref{subsec:hpa} alfejezetben bemutatott HPA skálázás esetén említésre került, hogy tetszőleges metrikák alapján is van lehetőségünk skálázni.
Alapértelmezetten és leginkább a mérések alatt általunk is használt processzor erőforrás igény alapján történő skálázás a legelterjedtebb megoldás.
Ezen metrikákat a klaszter automatikusan tudja gyűjteni, így a skálázók konfigurációja és elindítása egyszerű folyamattá tud válni.
Illetve a legtöbb esetben, ha a klaszterünkben nincsenek szűkös erőforráshatárok aránylag jó működést eredményez.

A megoldási lehetőség hátránya, hogy ezen implementáció is lokálisan az egyes alkalmazásegységek skálázását fogja végezni.
Így pedig, amikor az erőforrások allokációja nagymértékű nem képes a rendszer áteresztőképességét figyelembe venni.

Továbbra sincs dinamikus algoritmus a skálázó mögött, így az indítás pillanatában beállított konfigurációk alapján fogja meghozni a beavatkozási döntéseket.
Emiatt a kezdeti konfigurációnál nagyon alaposan végig kell gondolni, hogy milyen szabályokat szeretnénk alkalmazni.
Esetlegesen rosszul felmért metrikák alapján többlet erőforrásokat is lefoglalhatunk a kiszolgálási metrikák javulása nélkül.

A megoldás felvetése, hogy az alkalmazás logikai rétegében legyenek követve, mentve és exportálva olyan metrikák, melyek később az alsóbb szintű infrastruktúra réteg működését fogják befolyásolni.
Ezt szintén mérlegelni kell, hiszen nem tartozik szorosan az alkalmazás logikai részéhez illetve bizonyos mértékű többlet fejlesztést is igényel.

\subsection{Szolgáltatás hálók által nyújtott lehetőségek}
%----------------------------------------------------------------------------
Több új kihívás is megjelent a mikroszolgáltatások elterjedésével, amivel szembe kellett nézni a fejlesztőknek és az üzemeltetőknek is.
Ezen kihívások mentén született meg a szolgáltatás hálók (\textit{service mesh}) fogalma. 
Fontos megjegyezni, hogy a fejezetben tárgyalt szolgáltatás háló kifejezés a dolgozatban szereplő többi előfordulásán túl egyéb megkötéseket is tartalmaz.
Emiatt szeretném tisztázni, hogy a következőkben használt szolgáltatás háló alatt mit értünk.

A szolgáltatás háló egy lehetséges módja, hogy szabályozzuk az alkalmazásrészek közti kommunikációt. 
Külön infrastruktúra réteget tudunk létrehozni, amin keresztül láthatjuk és szabályozhatjuk a komponensek közti kommunikációt.
Ezzel lehetőséget kapunk a kommunikáció optimalizációjára, amivel együtt az esetleges kieséseket is csökkenthetjük\citep{serviceMeshDefinition}.

Az egyes alkalmazás komponenseket nevezzük egy-egy szolgáltatásnak, és a kommunikációjuk által alkothatunk belőlük hálózatot.
Több megvalósítás is létezik, azonban a felépítésük nagyon hasonlít.
Egy ilyen architektúra bemutatása látható \aref{fig:serviceMesh-topology} ábrán.

% Service Mesh Topology -------------------------------------------------------
\begin{figure}[!ht]
\centering
\includegraphics[width=150mm, keepaspectratio]{figures/service-mesh-generic-topology.png}
\caption{Szolgáltatás hálót alkotó komponensek és működésük\citep{serviceMeshTopology}}
\label{fig:serviceMesh-topology}
\end{figure}

Az ábrán \textit{Instance A/B/C} névvel ellátott alkalmazás egységek valósítanak meg egy-egy szolgáltatást az elképzelt mikroszolgáltatás architektúrában. 
Jól látható, hogy köztük nem történik semmilyen közvetlen kommunikáció, csak a mellettük lévő oldalkocsival (\textit{sidecar}) vannak kapcsolatban.
Ezek az oldalkocsik tipikusan egy konfigurálható proxyt tartalmaznak és az adott szolgáltatás mellett üzemelnek.
Ezt a mintát nevezik a oldalkocsis mintának (\textit{sidecar pattern})\citep{sidecarPattern}.
Minden, a szolgáltatások által küldött és fogadott kérésnek keresztül kell menni ezen a proxyn, ami pedig így belelátást kap a csomagokba illetve azok továbbítására is ráhatása van.
Ezáltal nyomon követhető és megfigyelhető lesz a komponensek közti kommunikáció.
Ez önmagában is előnyös, hiszen könnyebben meg lehet tudni, hogy az egyes szolgáltatáshálók milyen kiszolgálást tudnak nyújtani, könnyebb kideríteni az aktuálisan legszűkebb keresztmetszetet.
Természetesen a rendszerbe kötött proxykat kezelni is kell, amire egy külön réteg van, azonban ez már nagyobb mértékben specifikus az egyes megvalósításokra.

Az új architektúra is rendelkezik bizonyos megkötésekkel, amit az alkalmazása előtt figyelembe kell venni.
Mivel új komponenseket hozunk be a kommunikációba, ezért a késleltetések is meg fognak nőni.
Továbbá megfontolandó, hogy a proxyk működtetése is többlet erőforrás-használatot fog eredményezni. 
Természetesen növelni fogja a processzor foglaltságot és használtságot, valamint az alkalmazás futtatásához memóriára lesz szükség.
További hátránya, ami egyben az előnye is, hogy egy új komplexitást hoz be az amúgy is összetett alkalmazás üzemeltetésbe. 
Ezért az architekturális döntés meghozatalában körültekintően kell eljárni.


%\subsubsection{Gloo Edge}
% Other ingress controller
%TODO
%----------------------------------------------------------------------------
%- Ingress controller - hivetkozás
%- Mivel tud kevesebbet, mint a service mesh

\subsection{Okos skálázó}
%----------------------------------------------------------------------------

A korábban bemutatott megoldási lehetőségeknél, \ref{subsec:container_metric_scaling} alfejezetben látottat leszámítva, a fő motiváció a beérkező terhelés szabályozása volt.
Az eredeti problémánkat viszont több irányból is meg lehet fogni.
Másik megközelítésben az erőforrások globálisan optimális elosztása a fő szempont, a megoldandó kihívás.

A következő megoldási javaslat ezt a megközelítést veszi alapul és bővíti ki a korábban látott javaslatokkal.
A javaslat egy központi skálázó alkalmazás, ami folyamatosan monitorozza a klaszter teljes állapotát és az éppen futtatott alkalmazásokat is.
A skálázási javaslatokat pedig ezen információk összességéből tudja meghatározni.
Így figyelembe tudja venni az egyes kapszulák minőségi osztály besorolásuktól kezdve az egyes komponensek közti forgalmak megosztásán keresztül az esetlegesen exportált alkalmazás metrikákig.

Ezzel a megoldással lehetőségünk lenne az alkalmazás egységek kezelése helyett a teljes rendszer számára ideális döntéseket meghozni.
Akár több névtérben futó rendszerek erőforrás allokációit is össze lehet hangolni, ami további optimalizálást jelentene.

A bemutatott javaslatok közül ez a megoldás a legkomplexebb is. 
Ez egyértelműen a Kubernetes platform nyílt forráskódjának bővítésével járna.
Egy ilyen projekt jelentős szakmai erőforrás ráfordításával járna, hiszen az újfajta skálázóhoz új erőforrásokat is létre kell hozni illetve a kezeléshez szükséges logikát implementálni is kell.

Nem elhanyagolható felvetés, hogy a skálázási algoritmus logikájának bonyolítása jelentős kockázatokkal járhat, ha annak paraméterezését a felhasználóra bízzuk.

\paragraph{Analitikus modell}
Az okos skálázó optimális működéséhez szükséges jobban megvizsgálni a horizontális skálázás hatását.
A vizsgálandó kérdés, hogy egy szolgáltatáshálóban elvégzett skálázás milyen kihatással bír a többi komponensre, és a teljes rendszer kiszolgálási értékei hogyan alakulnak.
Meg kellett vizsgálni, hogy milyen összefüggés figyelhető meg a futtatott podok száma és az általuk kiszolgált másodpercenkénti kérések száma között.

Az alap feltevés látható \aref{eq:maxQPS} egyenleten, ahol $f()$ függvény adja meg, hogy mennyi kiszolgálást tud teljesíteni az adott komponens az $n$-nel jelzett podok függvényében.
Az $f()$ függvényt nem ismerjük, teljesen alkalmazásspecifikus, azonban a maximálisan elviselt terhelést a mérések alapján és $n$-et igen.

A feltevés az, hogy ezen ismeretekkel becsülhető a skálázás utáni kiszolgált másodpercenkénti maximális kérések száma, melyet $Q'$ jelöl. 
Ezt úgy kaphatjuk, meg, hogy az ismert $Q$ értékét elosztjuk az azt kiszolgáló kapszulák számával ($n$), amivel megkapjuk, hogy hozzávetőlegesen egy pod mennyi kérést tud kiszolgálni azonos konfigurációk mellett.
Majd az így kapott eredményt felszorozzuk a skálázás utáni podok számával, ami $n'$. 

\begin{equation} \label{eq:maxQPS}
\begin{split}
f(n) & = Q \\
f(n') & = \frac{Q}{n} * n' = Q' 
\end{split}
\end{equation}

A tézis ellenőrzése szimuláción keresztül történt.
A szolgáltatáshálóban egy gyors és erőforrás hatékony frontend szerepelt és utána pedig egy erőforrás-igényes backend. 
A backend számának növelésével szimuláltam a horizontális skálázás működését.
A kapott eredmények láthatóak \aref{fig:analitic-model} ábrán.

A legfelső[\ref{subfig:model-1FE-1BE}] grafikon mutatja azt az esetet, amikor egy darab backend konténer szolgálta ki az összes frontend felől érkező kérést.
Leolvasható, hogy ebben az esetben körülbelül 35 QPS terhelés mellett sikerült időben kiszolgálni az össze beérkező kérést.

Amikor két példányban indult el a backend komponens, akkor az elvárt módon meg is ugrik az időben kiszolgálható lekérdezések száma.
A grafikonról[\ref{subfig:model-1FE-2BE}] leolvasva az így kapott QPS érték 66 körül alakul, de nem éri el a 70-et.

Végül pedig az látható az alsó grafikonon[\ref{subfig:model-1FE-3BE}], amikor három példány fogadta a backend felé érkező kéréseket.
Ebben az esetben nagyjából 108 kérés kiszolgálása vált lehetővé.

A kapott eredményekből látható, hogy visszaosztva az egyes méréseknél kapott maximális QPS értéket a futtatott backend podok számával megkapjuk, hogy egy kapszula 33-36 kérés kiszolgálását tudja elvégezni.
Ez az érték kismértékben eltér az egyes szimulációkban, azonban kellően statikus marad végig, hogy modellként alkalmazzuk.


\begin{figure}
\centering
\begin{subfigure}{\textwidth}
    \includegraphics[width=\textwidth]{figures/analitic-model/1FE-1BE.png}
    \caption{Válaszidők egy frontend és egy backend egység esetén}
    \label{subfig:model-1FE-1BE}
\end{subfigure}

\hfill
\begin{subfigure}{\textwidth}
    \includegraphics[width=\textwidth]{figures/analitic-model/1FE-2BE.png}
    \caption{Válaszidők egy frontend és két backend egység esetén}
    \label{subfig:model-1FE-2BE}
\end{subfigure}

\hfill
\begin{subfigure}{\textwidth}
    \includegraphics[width=\textwidth]{figures/analitic-model/1FE-3BE.png}
    \caption{Válaszidők egy frontend és három backend egység esetén}
    \label{subfig:model-1FE-3BE}
\end{subfigure}

        
\caption{Túlterhelt elem skálázása utáni kiszolgálási válaszidők}
\label{fig:analitic-model}
\end{figure}

%\subsection{HPA és VPA skálázó}
%----------------------------------------------------------------------------
%Az alapképzés végén készített szakdolgozatom 

%Az okosított skálázó hátrányainál is szerepel, hogy igazán specifikus működést csak kellően nagyszámú konfigurációval lehet elérni, ami vis

%Namespacek között

%fejlesztés, tesztelés

%pl: nyomon követi milyen arányban használják az erőforrásokat

%Amdahl's törvényt is figyelembe  veszi
%VPA és HPA együtt működik
%Szimulációk futtatására is ideális a rendsezr